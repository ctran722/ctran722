import argparse,re, os, csv, pysam 
#Example use is 
# python3 parseFastq.py --fastq /home/rbif/week6/hawkins_pooled_sequences.fastq
#created variables to check and create folders and files
folder=('fastqs')
folder2=('bam')
subfolder=('bam/sam')
control=('bam/sam/dgorgon_reference.fa')
check_folder=os.path.isdir(folder)
check_folder2=os.path.isdir(folder2)
check_folder3=os.path.isdir(subfolder)
check_file=os.path.isfile(control)
#if statements to creat folders and files if they do not exist
if not check_folder:
    os.mkdir(folder)
    print(folder, 'Directory has been created.')
else:
    print(folder, 'Directory already exists.')

if not check_folder2:
    os.mkdir(folder2)
    print(folder2, 'Directory has been created.')
else:
    print(folder2, 'Directory already exists.')

if not check_folder3:
    os.mkdir(subfolder)
    print(subfolder, 'Directory has been created.')
else:
    print(subfolder, 'Directory already exists.')
if not check_file:
    os.system('cp dgorgon_reference.fa bam/sam')
    print('dgorgon_reference.fa has been created.')
else :
    print('dgorgon_reference.fa already exists.')
#indicting the start of creating fastq files.
print('Creating corresponding fastq files.')

################################################
#copied parseFastq.py scirpt 
# You can use this code and put it in your own script
class ParseFastQ(object):
    """Returns a read-by-read fastQ parser analogous to file.readline()"""
    def __init__(self,filePath,headerSymbols=['@','+']):
        """Returns a read-by-read fastQ parser analogous to file.readline().
        Exmpl: parser.next()
        -OR-
        Its an iterator so you can do:
        for rec in parser:
            ... do something with rec ...
 
        rec is tuple: (seqHeader,seqStr,qualHeader,qualStr)
        """
        if filePath.endswith('.gz'):
            self._file = gzip.open(filePath)
        else:
            self._file = open(filePath, 'rU')
        self._currentLineNumber = 0
        self._hdSyms = headerSymbols
         
    def __iter__(self):
        return self
     
    def __next__(self):
        """Reads in next element, parses, and does minimal verification.
        Returns: tuple: (seqHeader,seqStr,qualHeader,qualStr)"""
        # ++++ Get Next Four Lines ++++
        elemList = []
        for i in range(4):
            line = self._file.readline()
            self._currentLineNumber += 1 ## increment file position
            if line:
                elemList.append(line.strip('\n'))
            else: 
                elemList.append(None)
         
        # ++++ Check Lines For Expected Form ++++
        trues = [bool(x) for x in elemList].count(True)
        nones = elemList.count(None)
        # -- Check for acceptable end of file --
        if nones == 4:
            raise StopIteration
        # -- Make sure we got 4 full lines of data --
        assert trues == 4,\
               "** ERROR: It looks like I encountered a premature EOF or empty line.\n\
               Please check FastQ file near line number %s (plus or minus ~4 lines) and try again**" % (self._currentLineNumber)
        # -- Make sure we are in the correct "register" --
        assert elemList[0].startswith(self._hdSyms[0]),\
               "** ERROR: The 1st line in fastq element does not start with '%s'.\n\
               Please check FastQ file near line number %s (plus or minus ~4 lines) and try again**" % (self._hdSyms[0],self._currentLineNumber) 
        assert elemList[2].startswith(self._hdSyms[1]),\
               "** ERROR: The 3rd line in fastq element does not start with '%s'.\n\
               Please check FastQ file near line number %s (plus or minus ~4 lines) and try again**" % (self._hdSyms[1],self._currentLineNumber) 
        # -- Make sure the seq line and qual line have equal lengths --
        assert len(elemList[1]) == len(elemList[3]), "** ERROR: The length of Sequence data and Quality data of the last record aren't equal.\n\
               Please check FastQ file near line number %s (plus or minus ~4 lines) and try again**" % (self._currentLineNumber) 
         
        # ++++ Return fatsQ data as tuple ++++
        return tuple(elemList)
##########################################################################

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("-f", "--fastq", required=True, help="Place fastq inside here")
    args = parser.parse_args()

    #This is an example of how to use the function in your own code
    
    fastqfile = ParseFastQ(args.fastq)
    
    #A fastq read contains 4 lines
    #started to add and adjust codes here.
    #added a dictionary here to take advantage of looping the names and barcodes
    for fastq_obj in fastqfile:
        bcode={}
        with open('harrington_clinical_data.txt', 'r') as f:
            reader = csv.reader(f, delimiter='\t') 
            next(reader)
            for row in reader:
                Name=row[0]
                Color=row[1]
                Barcode=row[2]
                #This fastq_obj is a tuple that has length of 4 and corresponds to those 4 lines
                
                #created if statment to matching with  regular expression from the dictionary barcode per each line of sequencne (fastq_obj[1] is the sequence)
                #print statements were left for sanity checks to ensure the correct sequence was generated
                if re.match(Barcode, fastq_obj[1]):
                    #writing the fastq files to append the created data per each sample
                    f=open('fastqs/%s_trimmed.fastq' %(Name),"a" ) 
                    
                    #This is the header
                    Header=fastq_obj[0]
                    #print(fastq_obj[0])
                    
                    #This is the sequence that has been cut by the barcode and Quality score to match. 222 was the length of the quality score so to correspond along with the barcodes 5 more characters were added.
                    Sequence=(fastq_obj[1][5:227])
                    #print(fastq_obj[1])
                    #print((fastq_obj[1][5:227]))
                    #print(len(fastq_obj[1][5:227]))
                    
                    #This is the separator
                    Separator=(fastq_obj[2])
                    #print(fastq_obj[2])
                    
                    #This is the quality score Len was used to find the length of the quality score for sequence while split was used to cut the patterns the string was to call the split which was the 0 index 
                    #length of the Quality score is 222.
                    Quality_score= (str(re.split('DF|FF|FD|DD', fastq_obj[3])[0]))
                    #print(str(re.split('DF|FF|FD|DD', fastq_obj[3])[0]))
                    #print(len(str(re.split('DF|FF|FD|DD', fastq_obj[3])[0])))
                    #print(fastq_obj[3])
                   
                    #Just an indicator showing the fastq "blocks"
                    fastq_blocks=('*'*10 + '==='*10 + '*' * 10)
                    #print('*'*10 + '==='*10 + '*' * 10)
                    #writing the data to the corresponding data per each sample
                    f.write("{}\n{}\n{}\n{}\n\n".format(Header, Sequence, Separator, Quality_score,fastq_blocks))
                    #print("Completed %s_trimed.fastq file" %(Name))
                    #closing the file for each fastq
                    f.close()
#indicting the completion of fastq files.
print("Fastq files are complete.")

#indicting the start of creating sam and bam files.
print("Creating corresponding sam and bam files.")
#Recreated dictionary to take advantage of Names for string Putting this inside the fastq loop will cause an incredibly long loop             
with open('harrington_clinical_data.txt', 'r') as f:
    reader = csv.reader(f, delimiter='\t') 
    next(reader)
    for row in reader:
        Names=row[0]
        Colors=row[1]
        Barcodes=row[2]
        #created variables to use to set bash command to call bash scripts to convert and index sam and bam files 
        fastq= '%s_trimmed.fastq' %(Names) 
        Reference='bwa index bam/sam/dgorgon_reference.fa'
        Samfile= ('bwa mem bam/sam/dgorgon_reference.fa fastqs/%s_trimmed.fastq > bam/sam/%s.sam' %(Names, Names))
        Bam=('samtools view -bS bam/sam/%s.sam > bam/%s.bam' % (Names, Names))
        Bamsort=('samtools sort -m 100M -o bam/%s.sorted.bam bam/%s.bam ' %(Names,Names))
        Bamindex=('samtools index bam/%s.sorted.bam' %(Names))
        
        #used os.system to call  bash commands in variables to convert and index sam and bam files
        #indexing is necessary to align and location for the mutation script
        os.system(Reference)
        os.system(Samfile) 
        os.system(Bam)
        os.system(Bamsort)
        os.system(Bamindex)
#indicting the completion of bam and sam files.
print("Sam and bam files are complete.")

#initiating the start of the report.
print('Creating sequencing report. Results will be shown below.')
#Recreated dictionary to take advantage of Names for string Putting this inside the os loop stopped the scripted.       
with open('harrington_clinical_data.txt', 'r') as f:
    reader = csv.reader(f, delimiter='\t') 
    next(reader)
    for row in reader:
        Name=row[0]
        Color=row[1]
        Barcode=row[2]

#copied script from getMutations.py
#This is a slightly modified version from here: https://pysam.readthedocs.io/en/latest/api.html
# What is a pileup? It is "piling up" all the reads that have mapped to a given position of your reference.
# It is a useful way to see what reads have a mutation and what don't. 
        def pileup():
    #test file, replaced with the sorted.bam you are using. Make sure it is indexed! (Use samtools index yourbam.sorted.bam)
            samfile = pysam.AlignmentFile("bam/%s.sorted.bam"%(Name), "rb")
    #Since our reference only has a single sequence, we're going to pile up ALL of the reads. Usually you would do it in a specific region (such as chromosome 1, position 1023 to 1050 for example)
            for pileupcolumn in samfile.pileup():
                #print ("coverage at base %s = %s" % (pileupcolumn.pos, pileupcolumn.n))
                
                #use a dictionary to count up the bases at each position
                #readjusted dictionary to add keys needed for report
                ntdict = {'nt':[], pileupcolumn.pos:[], pileupcolumn.n:[], 'A':[],'T':[],'G':[],'C':[]}
                for pileupread in pileupcolumn.pileups:
                    if not pileupread.is_del and not pileupread.is_refskip:
                # You can uncomment the below line to see what is happening in the pileup. 
                        #print ('\tbase in read %s = %s' % (pileupread.alignment.query_name, pileupread.alignment.query_sequence[pileupread.query_position]))
                        base = pileupread.alignment.query_sequence[pileupread.query_position]
                ########## ADD ADDITIONAL CODE HERE ############# 
                #left print statements commented as they were left for santity checks
                    #appended ntdict with the base variable
                    ntdict['nt'].append(base)
                    # print(ntdict['nt'])
                    #created if and elf statements to append corresponding bases to corresponding keys
                    #left print statements commented as they were left for santity checks 
                    if base == 'A':
                        ntdict['A'].append(base)
                        #print(ntdict['A'])
                    elif base == 'T':
                        ntdict['T'].append(base)
                        #print(ntdict['T'])
                    elif base =='C':
                        ntdict['C'].append(base)
                        #print(ntdict['C'])
                    elif base == 'G':
                        ntdict['G'].append(base)
                        #print(ntdict['G'])
                    
                    #created variables for corresponding counts 
                    #left print statements commented as they were left for santity checks
                    Counta=(ntdict['A'].count('A'))
                    # print(Counta)
                    Countt=(ntdict['T'].count('T'))
                    # print(Countt)
                    Countc=(ntdict['C'].count('C'))
                    # print(Countc)
                    Countg=(ntdict['G'].count('G'))
                    # print(Countg)
                    
                    # total varibale will help calcuate the fequency of each nucleotide
                    #left print statements commented as they were left for santity checks
                    total =(Counta+Countt+Countc+Countg)
                    # print(total)
                    
                    #fequency of each nucleotide was created to help determine the mutation.
                    #left print statements commented as they were left for santity checks
                    feqa=((Counta/total)*100)
                    # print(feqa)
                    feqt=((Countt/total)*100)
                    # print(feqt)
                    feqc=((Countc/total)*100)
                    # print(feqc)
                    feqg=((Countg/total)*100)
                    # print(feqg)

                    #creating a report.txt to report the mutations
                    #Note mutations are reported if frequency of nucleotides are not 100% or 0%
                    r=open('report.txt',"a" )
                    #if and elif for all(A,T,C,G) frequency statements were created to meet the conditions, if samples were not 100% or 0% frequency, the sample will be added to the report and printed in the terminal
                    #left print statements for santity checks and to show the results while the program was running
                    if feqa != 0.0 and feqa != 100.0:
                        if ntdict['nt'][0] != ntdict['A'][0]:
                            print(("%s's  %s mold sample  mutated on %s at base position  %s with  %s reads. The nucleotide mutated of %s to %s. \n" % (Name, Color, pileupread.alignment.query_name, pileupcolumn.pos, (pileupcolumn.n), ntdict['A'][0], ntdict['nt'][0])))
                            #if sample hits all requirements, the sample will be reported. This holds for all the elf statments below.
                            r.write(("%s's  %s mold sample  mutated on %s at base position  %s with  %s reads. The nucleotide mutated of %s to %s. \n" % (Name, Color, pileupread.alignment.query_name, pileupcolumn.pos, (pileupcolumn.n), ntdict['A'][0], ntdict['nt'][0])))
                            #the break is to end the loop since each read will be read for that sequence multiple times. This holds for all the elif and if statments below.
                            break
                    elif feqt != 0.0 and feqt != 100.0:
                        if ntdict['nt'][0] != ntdict['T'][0]:
                            print(("%s's  %s mold sample  mutated on %s at base position  %s with  %s reads. The nucleotide mutated of %s to %s. \n" % (Name, Color, pileupread.alignment.query_name, pileupcolumn.pos, (pileupcolumn.n), ntdict['T'][0], ntdict['nt'][0])))
                            r.write(("%s's  %s mold sample  mutated on %s at base position  %s with  %s reads. The nucleotide mutated  of %s to %s. \n" % (Name, Color, pileupread.alignment.query_name, pileupcolumn.pos, (pileupcolumn.n), ntdict['T'][0], ntdict['nt'][0])))
                            break
                    elif feqc != 0.0 and  feqc != 100.0:
                            if ntdict['nt'][0] != ntdict['C'][0]:
                                print(("%s's  %s mold sample  mutated on %s at base position  %s with  %s reads. The nucleotide mutated from %s to %s. \n" % (Name, Color, pileupread.alignment.query_name, pileupcolumn.pos, (pileupcolumn.n), ntdict['C'][0], ntdict['nt'][0])))
                                r.write(("%s's  %s mold sample  mutated on %s at base position  %s with  %s reads. The nucleotide mutated from  %s to %s. \n" % (Name, Color, pileupread.alignment.query_name, pileupcolumn.pos, (pileupcolumn.n), ntdict['C'][0], ntdict['nt'][0])))
                                break
                            elif feqg != 0.0 and feqg != 100.0:
                                if ntdict['nt'][0] != ntdict['G'][0]:
                                    print(("%s's  %s mold sample  mutated on %s at base position  %s with  %s reads. The nucleotide mutated from %s to %s. \n" % (Name, Color, pileupread.alignment.query_name, pileupcolumn.pos, (pileupcolumn.n), ntdict['G'][0], ntdict['nt'][0])))
                                    r.write(("%s's  %s mold sample  mutated on %s at base position  %s with  %s reads. The nucleotide mutated from %s to %s. \n" % (Name, Color, pileupread.alignment.query_name, pileupcolumn.pos, (pileupcolumn.n), ntdict['G'][0], ntdict['nt'][0])))
                                    break
            
                # Populate the ntdict with the counts of each base 
                # This dictionary will hold all of the base read counts per nucletoide per position.
                # Use the dictionary to calculate the frequency of each site, and report it if if the frequency is NOT  100% / 0%. 
                #############################################
                # print (ntdict)
            #closing out the written report.txt and samfile
            r.close() 
            samfile.close()
    
        if __name__=="__main__":
            pileup()
#printing out the sequecing analysis is complete and the results can be reviewed in the Report.txt file
print('Sequencing analysis complete. Please review report.txt for the results.')